import os
import shutil
from PIL import Image
from PIL.ExifTags import TAGS
import datetime
import subprocess
import concurrent.futures
import logging
import time
from functools import lru_cache
import sys
import hashlib
import threading
import math
from collections import deque

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)


# è¿›åº¦æ¡ç±»
class ProgressBar:
    def __init__(self, total, desc="å¤„ç†ä¸­", bar_length=50, unit='æ–‡ä»¶'):
        self.total = total
        self.desc = desc
        self.bar_length = bar_length
        self.unit = unit
        self.lock = threading.Lock()
        self.start_time = time.time()
        self.completed = 0
        self.last_update = 0
        self.speed_history = deque(maxlen=10)  # é€Ÿåº¦å†å²ï¼ˆå¹³æ»‘æ˜¾ç¤ºï¼‰

        # åˆå§‹æ˜¾ç¤º
        if total > 0:
            self._print()

    def update(self, num=1):
        """æ›´æ–°è¿›åº¦"""
        with self.lock:
            self.completed += num
            current_time = time.time()
            elapsed = current_time - self.last_update

            # æ¯0.2ç§’æˆ–å½“å®Œæˆæ—¶æ›´æ–°ä¸€æ¬¡ï¼Œé¿å…åˆ·æ–°å¤ªé¢‘ç¹
            if elapsed >= 0.1 or self.completed >= self.total:
                self._print()
                self.last_update = current_time

    def increment(self):
        """å¢åŠ ä¸€ä¸ªå®Œæˆé¡¹ï¼ˆç®€åŒ–æ–¹æ³•ï¼‰"""
        self.update(1)

    def _format_speed(self):
        """è®¡ç®—å¹¶æ ¼å¼åŒ–å¤„ç†é€Ÿåº¦"""
        total_elapsed = time.time() - self.start_time
        if total_elapsed > 0:
            items_per_sec = self.completed / total_elapsed
            self.speed_history.append(items_per_sec)
            avg_speed = sum(self.speed_history) / len(self.speed_history)

            # æ ¹æ®é€Ÿåº¦å¤§å°é€‰æ‹©é€‚å½“çš„å•ä½
            if avg_speed > 100:
                return f"{avg_speed:.0f} {self.unit}/ç§’"
            elif avg_speed > 0.1:
                return f"{avg_speed:.1f} {self.unit}/ç§’"
            else:
                return f"{avg_speed:.2f} {self.unit}/ç§’"
        return ""

    def _print(self):
        """æ‰“å°å½“å‰è¿›åº¦æ¡"""
        if self.total == 0:
            return

        progress = min(1.0, self.completed / self.total)
        filled_length = int(round(self.bar_length * progress))

        # åˆ›å»ºè¿›åº¦æ¡å­—ç¬¦ä¸²
        bar = 'â–“' * filled_length + 'â–‘' * (self.bar_length - filled_length)
        percent = min(100.0, progress * 100.0)

        ratio_str = f"{self.completed}/{self.total}"
        speed_str = self._format_speed()
        time_remaining = self._calc_remaining() if progress > 0 else "è®¡ç®—ä¸­..."

        # æ„å»ºå®Œæ•´è¾“å‡ºè¡Œ
        line = f"\r{self.desc}: {percent:5.1f}% |{bar}| {ratio_str} {speed_str} (å‰©ä½™: {time_remaining})"

        # ç¡®ä¿è¡Œå°¾æ¸…é™¤å…¶ä»–å­—ç¬¦
        clear_length = max(80, self.bar_length + 80)
        spaces = " " * clear_length
        print(f"\r{spaces}\r{line}", end='', flush=True)

        # å½“å®Œæˆæ—¶æ¢è¡Œ
        if self.completed >= self.total:
            print()

    def _calc_remaining(self):
        """è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´"""
        elapsed = time.time() - self.start_time
        if self.completed > 0 and elapsed > 0:
            time_per = elapsed / self.completed
            remaining = time_per * (self.total - self.completed)

            # æ ¼å¼åŒ–å‰©ä½™æ—¶é—´ä¸ºç”¨æˆ·å‹å¥½çš„æ ¼å¼
            if remaining < 60:  # ç§’çº§
                return f"{remaining:.0f}ç§’"
            elif remaining < 3600:  # åˆ†é’Ÿçº§
                return f"{remaining / 60:.1f}åˆ†é’Ÿ"
            else:  # å°æ—¶çº§
                return f"{remaining / 3600:.1f}å°æ—¶"
        return ""

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.total > 0 and self.completed < self.total:
            self._print()  # ç¡®ä¿å³ä½¿æœªå®Œæˆä¹Ÿæ˜¾ç¤ºæœ€åçŠ¶æ€
        return False


# ä¼˜åŒ–å¸¸é‡
IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.heic', '.tiff', '.nef', '.cr2', '.arw', '.dng')
VIDEO_EXTENSIONS = ('.mp4', '.mov', '.avi', '.mkv', '.flv', '.wmv', '.3gp', '.m4v', '.mts', '.mpg', '.mpeg')
ALL_EXTENSIONS = IMAGE_EXTENSIONS + VIDEO_EXTENSIONS

# æ‰©å±•åå­—å…¸ç”¨äºå¿«é€ŸæŸ¥æ‰¾
EXT_MAP = {ext: 1 for ext in ALL_EXTENSIONS}


# çº¿ç¨‹å®‰å…¨çš„ç»Ÿè®¡å¯¹è±¡
class ProcessingStats:
    def __init__(self, total_files):
        self.lock = threading.Lock()
        self.files_moved = 0
        self.files_skipped = 0
        self.files_failed = 0
        self.files_processed = 0
        self.total_files = total_files
        self.start_time = time.time()
        self.last_log_time = self.start_time
        self.last_count = 0

    def moved(self):
        with self.lock:
            self.files_moved += 1
            self.files_processed += 1

    def skipped(self):
        with self.lock:
            self.files_skipped += 1
            self.files_processed += 1

    def failed(self):
        with self.lock:
            self.files_failed += 1
            self.files_processed += 1

    def get_stats(self):
        with self.lock:
            elapsed = time.time() - self.start_time
            return {
                'moved': self.files_moved,
                'skipped': self.files_skipped,
                'failed': self.files_failed,
                'processed': self.files_processed,
                'elapsed': elapsed,
                'total': self.total_files
            }

    def log_progress(self, force=False):
        """è®°å½•è¿›åº¦ï¼ˆæ¯åˆ†é’Ÿæˆ–å½“å¼ºåˆ¶æ—¶ï¼‰"""
        current_time = time.time()
        with self.lock:
            if force or (current_time - self.last_log_time > 60 or self.files_processed == self.total_files):
                percent = (self.files_processed / self.total_files) * 100
                speed = (self.files_processed - self.last_count) / max(1, current_time - self.last_log_time)

                logger.info(
                    f"è¿›åº¦: {percent:.1f}% ({self.files_processed}/{self.total_files}) | "
                    f"é€Ÿåº¦: {speed:.1f}æ–‡ä»¶/ç§’ | "
                    f"æˆåŠŸ: {self.files_moved} | "
                    f"è·³è¿‡: {self.files_skipped} | "
                    f"å¤±è´¥: {self.files_failed}"
                )

                self.last_log_time = current_time
                self.last_count = self.files_processed


def setup_logging(verbose=False):
    """é…ç½®æ—¥å¿—çº§åˆ«"""
    log_level = logging.DEBUG if verbose else logging.INFO
    logger.setLevel(log_level)


@lru_cache(maxsize=4096)
def get_cached_file_timestamp(filepath):
    """å¸¦ç¼“å­˜çš„æ–‡ä»¶ä¿®æ”¹æ—¶é—´è·å–ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
    try:
        return os.path.getmtime(filepath)
    except Exception:
        return time.time()


@lru_cache(maxsize=4096)
def get_image_exif_date(image_path):
    """ä»å›¾ç‰‡EXIFè·å–æ—¥æœŸï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    try:
        with Image.open(image_path) as img:
            exif_data = img.getexif()

            if not exif_data:
                return None

            # é¢„å®šä¹‰çš„æ—¥æœŸæ ‡ç­¾IDåˆ—è¡¨
            date_tag_ids = {
                36867: "DateTimeOriginal",  # EXIFæ—¥æœŸæ—¶é—´åŸå§‹å€¼
                36868: "DateTimeDigitized",  # EXIFæ•°å­—åŒ–æ—¥æœŸæ—¶é—´
                306: "DateTime",  # TIFF/EP æ ‡å‡†æ—¥æœŸæ—¶é—´

                # ç›¸æœºç‰¹å®šæ ‡ç­¾
                50934: "OlympusDate",  # Olympusæ—¥æœŸæ—¶é—´
                50937: "OlympusDateTime",  # Olympusæ—¥æœŸæ—¶é—´(é•¿æ ¼å¼)
                32781: "DateTimeCreated",  # åˆ›å»ºæ—¥æœŸæ—¶é—´(æŸäº›ç›¸æœº)
            }

            for tag_id, tag_name in date_tag_ids.items():
                value = exif_data.get(tag_id)
                if value:
                    try:
                        # æ¸…ç†å¯èƒ½çš„é—®é¢˜å­—ç¬¦
                        clean_value = ''.join(c for c in value.strip() if c.isprintable())
                        # å°è¯•åˆ†å‰²æ—¥æœŸéƒ¨åˆ†
                        date_part = clean_value.split()[0]
                        return datetime.datetime.strptime(date_part[:10], "%Y-%m-%d").date()
                    except (ValueError, TypeError):
                        continue
    except Exception as e:
        logger.debug(f"EXIFè¯»å–é”™è¯¯ {os.path.basename(image_path)}: {str(e)}")
    return None


@lru_cache(maxsize=2048)
def get_video_metadata_date(video_path):
    """å¸¦ç¼“å­˜çš„è§†é¢‘å…ƒæ•°æ®æ—¥æœŸè·å–ï¼Œæ”¯æŒæ›´å¤šæ ¼å¼"""
    try:
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format_tags=creation_time :format_tags=creation_date',
            '-of', 'default=nokey=1:noprint_wrappers=1',
            video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)

        if result.returncode == 0:
            # å°è¯•è§£æè¾“å‡ºä¸­çš„æ—¥æœŸå€¼
            for date_str in result.stdout.splitlines():
                date_str = date_str.strip()
                if not date_str:
                    continue

                # å°è¯•æ‰€æœ‰å¯èƒ½çš„æ—¥æœŸæ ¼å¼
                formats = [
                    "%Y-%m-%dT%H:%M:%S",  # ISOæ ¼å¼ (GoPro/iPhone)
                    "%Y%m%d",  # ç´§å‡‘æ ¼å¼ (Sonyç›¸æœº)
                    "%Y/%m/%d %H:%M:%S",  # ç›®å½•/æ—¶é—´æ ¼å¼
                    "%d-%b-%Y",  # Nikonæ ¼å¼ (01-JAN-2023)
                    "%Y:%m:%d %H:%M:%S"  # EXIFæ ¼å¼çš„è§†é¢‘
                ]

                for fmt in formats:
                    try:
                        # æ¸…ç†ä¸è§„åˆ™å­—ç¬¦
                        clean_date = ''.join(c for c in date_str if c.isprintable())
                        # å¤„ç†æ—¶åŒº/å¾®ç§’éƒ¨åˆ†
                        date_parts = clean_date.split('.')[0].split('+')
                        dt_str = date_parts[0].replace('T', ' ')
                        dt = datetime.datetime.strptime(dt_str, fmt)
                        return dt.date()
                    except ValueError:
                        continue

        # å°è¯•ä»æ–‡ä»¶åè§£ææ—¥æœŸï¼ˆå¸¸è§äºæ•°ç ç›¸æœºï¼‰
        basename = os.path.basename(video_path)
        if len(basename) >= 8 and basename[:8].isdigit():
            try:
                year = int(basename[0:4])
                month = int(basename[4:6])
                day = int(basename[6:8])
                return datetime.date(year, month, day)
            except ValueError:
                pass

    except (FileNotFoundError, subprocess.TimeoutExpired, subprocess.CalledProcessError) as e:
        logger.debug(f"è§†é¢‘æ—¥æœŸè·å–å¤±è´¥ {os.path.basename(video_path)}: {str(e)}")
    return None


def get_media_date_fast(media_path):
    """ä¼˜åŒ–çš„æ—¥æœŸè·å–ç­–ç•¥ï¼ˆå¸¦ç¼“å­˜å’Œå›é€€ï¼‰"""
    try:
        lower_path = media_path.lower()
        ext = os.path.splitext(lower_path)[1].lower()

        # å›¾ç‰‡æ–‡ä»¶ä¼˜å…ˆå°è¯•EXIF
        if ext in IMAGE_EXTENSIONS:
            exif_date = get_image_exif_date(media_path)
            if exif_date:
                return exif_date

        # è§†é¢‘æ–‡ä»¶å°è¯•è·å–å…ƒæ•°æ®
        if ext in VIDEO_EXTENSIONS:
            video_date = get_video_metadata_date(media_path)
            if video_date:
                return video_date

        # å°è¯•ä»æ–‡ä»¶åè§£ææ—¥æœŸ
        basename = os.path.basename(media_path)

        # å¸¸è§æ–‡ä»¶åæ¨¡å¼ï¼ˆ20230105_123456.jpgï¼‰
        for pattern in ["%Y%m%d", "%Y-%m-%d", "%Y_%m_%d"]:
            if len(basename) >= 10:
                for start in range(0, max(1, len(basename) - 10)):
                    date_str = basename[start:start + 8]
                    if len(date_str) < 8:
                        continue

                    if pattern == "%Y_%m_%d" and date_str[4] == '_' and date_str[7] == '_':
                        date_str = date_str[:4] + date_str[5:7] + date_str[8:10]

                    if pattern == "%Y-%m-%d" and date_str[4] == '-' and date_str[7] == '-':
                        date_str = date_str[:4] + date_str[5:7] + date_str[8:10]

                    # éªŒè¯å¯èƒ½çš„æ—¥æœŸæ ¼å¼
                    if date_str.isdigit() and len(date_str) == 8:
                        year = int(date_str[0:4])
                        month = int(date_str[4:6])
                        day = int(date_str[6:8])

                        # éªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§ï¼ˆéä¸¥æ ¼éªŒè¯ï¼‰
                        if 1900 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:
                            return datetime.date(year, month, day)

        # æœ€åä½¿ç”¨ç¼“å­˜çš„æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        timestamp = get_cached_file_timestamp(media_path)
        return datetime.datetime.fromtimestamp(timestamp).date()
    except Exception as e:
        logger.debug(f"æ—¥æœŸè·å–é”™è¯¯ {os.path.basename(media_path)}: {str(e)}")
        return datetime.date(1970, 1, 1)  # å›é€€åˆ°epochæ—¶é—´


def generate_unique_filename(target_dir, base_name, extension):
    """ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆè§£å†³å†²çªï¼‰"""
    counter = 1
    base, orig_ext = os.path.splitext(base_name)
    if not extension:
        extension = orig_ext

    # é¦–é€‰åŸå§‹æ–‡ä»¶å
    new_filename = base_name

    while os.path.exists(os.path.join(target_dir, new_filename)):
        # å°è¯•è®¡æ•°å™¨
        new_filename = f"{base}_{counter}{extension}"
        counter += 1

        # å¦‚æœå†²çªä¸¥é‡ï¼Œæ·»åŠ çŸ­å“ˆå¸Œ
        if counter > 10:  # é˜²æ­¢æ— é™å¾ªç¯
            file_hash = hashlib.md5(f"{base}{time.time()}{counter}".encode()).hexdigest()[:6]
            new_filename = f"{base}_{file_hash}{extension}"

        # æœ€ç»ˆä¿æŠ¤
        if counter > 100:
            new_filename = f"{base}_{int(time.time())}{extension}"

    return os.path.join(target_dir, new_filename)


def file_hash(filepath, block_size=65536):
    """è®¡ç®—æ–‡ä»¶çš„å¿«é€Ÿå“ˆå¸Œå€¼ï¼ˆä»…æ–‡ä»¶å¼€å¤´ï¼‰"""
    hasher = hashlib.md5()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(block_size), b''):
            hasher.update(chunk)
            if hasher.digest_size > 0:  # åªè¯»16Kè¶³å¤Ÿè¯†åˆ«å·®å¼‚
                break
    return hasher.hexdigest()[:8]  # çŸ­å“ˆå¸Œå‡å°‘æ¯”è¾ƒå¼€é”€


def calculate_target_path(file_info, target_base_dir, stats, progress_bar=None):
    """è®¡ç®—æ–‡ä»¶çš„ç›®æ ‡è·¯å¾„ï¼ŒåŒæ—¶æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
    filename, source_path = file_info

    try:
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
        if not os.path.exists(source_path):
            logger.warning(f"æ–‡ä»¶å·²æ¶ˆå¤±: {filename} (è·³è¿‡)")
            stats.skipped()
            return None

        # è·å–æ–‡ä»¶å¤§å°ï¼ˆç”¨äºè¿›åº¦ç»Ÿè®¡ï¼‰
        file_size = os.path.getsize(source_path)

        # è®¡ç®—æ–‡ä»¶æ—¥æœŸå’Œç›®æ ‡æ–‡ä»¶å¤¹
        media_date = get_media_date_fast(source_path)
        date_folder = media_date.strftime("%Y-%m-%d")
        target_dir = os.path.join(target_base_dir, date_folder)
        os.makedirs(target_dir, exist_ok=True)

        # è·å–å®é™…æ‰©å±•å
        base, orig_ext = os.path.splitext(filename)
        ext_lower = orig_ext.lower()
        extension = None

        # æŸ¥æ‰¾å®é™…æ–‡ä»¶æ‰©å±•å
        for ext in ALL_EXTENSIONS:
            if filename.lower().endswith(ext):
                extension = ext
                break
        if extension is None:
            extension = orig_ext

        # åˆå§‹ç›®æ ‡è·¯å¾„
        target_path = os.path.join(target_dir, filename)

        # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(target_path):
            return (source_path, target_path, date_folder, file_size)

        # å¦‚æœå·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åŒæ–‡ä»¶
        if file_hash(source_path) == file_hash(target_path):
            logger.debug(f"è·³è¿‡é‡å¤æ–‡ä»¶: {filename}")
            stats.skipped()
            return None

        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        target_path = generate_unique_filename(target_dir, filename, extension)

        return (source_path, target_path, date_folder, file_size)

    except Exception as e:
        logger.error(f"è®¡ç®—è·¯å¾„å¤±è´¥ {filename}: {str(e)}", exc_info=False)
        stats.failed()
        return None
    finally:
        # æ›´æ–°è¿›åº¦æ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if progress_bar:
            progress_bar.increment()


def process_file(file_task, stats, progress_bar=None):
    """å®‰å…¨åœ°å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆç§»åŠ¨æ“ä½œï¼‰ï¼Œæ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
    if file_task is None:
        return False

    source_path, target_path, date_folder, file_size = file_task
    filename = os.path.basename(source_path)

    try:
        # åŒé‡æ£€æŸ¥æºæ–‡ä»¶
        if not os.path.exists(source_path):
            logger.warning(f"æºæ–‡ä»¶å·²æ¶ˆå¤±: {filename} (è·³è¿‡)")
            stats.skipped()
            return False

        # ç§»åŠ¨æ–‡ä»¶
        shutil.move(source_path, target_path)
        new_filename = os.path.basename(target_path)
        logger.info(f"âœ“ å·²ç§»åŠ¨: {filename} -> {date_folder}/{new_filename}")
        stats.moved()
        return True
    except Exception as e:
        logger.error(f"âœ— ç§»åŠ¨å¤±è´¥: {filename} - é”™è¯¯: {str(e)}", exc_info=False)
        stats.failed()
        return False
    finally:
        # æ›´æ–°è¿›åº¦æ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if progress_bar:
            progress_bar.increment()


def organize_media(source_dir, target_base_dir=None, verbose=False, max_workers=None):
    """ä¸»å‡½æ•°ï¼šæŒ‰æ—¥æœŸæ•´ç†åª’ä½“æ–‡ä»¶ï¼ˆå›¾ç‰‡+è§†é¢‘ï¼‰"""
    setup_logging(verbose)

    # è®¾ç½®ç›®æ ‡ç›®å½•
    if target_base_dir is None:
        target_base_dir = source_dir

    if not os.path.exists(target_base_dir):
        os.makedirs(target_base_dir)
        logger.info(f"åˆ›å»ºæ–°ç›®æ ‡ç›®å½•: {os.path.abspath(target_base_dir)}")

    logger.info(f"â­ å¼€å§‹åª’ä½“æ•´ç†ï¼ˆåŒ…å«è§†é¢‘ï¼‰ @ {os.path.abspath(source_dir)}")
    logger.info(f"ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯: Python {sys.version} on {sys.platform}")
    logger.info(f"âš™ï¸ é…ç½®: ç›®æ ‡ç›®å½•={os.path.abspath(target_base_dir)} | è¯¦ç»†æ¨¡å¼={'æ˜¯' if verbose else 'å¦'}")

    # 1. æ‰«æåª’ä½“æ–‡ä»¶
    logger.info("ğŸ” å¼€å§‹æ‰«æåª’ä½“æ–‡ä»¶...")
    start_scan = time.time()
    media_files = []
    total_size = 0
    skipped_dirs = []

    # ç”¨äºæ‰«æè¿›åº¦çš„è™šæ‹Ÿè¿›åº¦æ¡
    scan_stats = ProcessingStats(total_files=float('inf'))
    last_log_time = time.time()

    # é€’å½’æ‰«ææ‰€æœ‰æ–‡ä»¶
    for root, dirs, files in os.walk(source_dir):
        # è·³è¿‡ç³»ç»Ÿç›®å½•ï¼ˆä»¥.å¼€å¤´æˆ–ç‰¹æ®Šç›®å½•ï¼‰
        if os.path.basename(root).startswith('.') or os.path.basename(root) == '__MACOSX':
            skipped_dirs.append(root)
            continue

        for file in files:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_ext = os.path.splitext(file)[1].lower()
            if file_ext in EXT_MAP:
                file_path = os.path.join(root, file)
                file_size = 0

                try:
                    # è·å–æ–‡ä»¶å¤§å°
                    file_size = os.path.getsize(file_path)
                    total_size += file_size
                    # æ·»åŠ åˆ°å¤„ç†åˆ—è¡¨
                    media_files.append((file, file_path))
                except OSError:
                    pass  # è·³è¿‡æ— æ³•è®¿é—®çš„æ–‡ä»¶

                # æ¯éš”5ç§’æˆ–æ¯500ä¸ªæ–‡ä»¶è®°å½•ä¸€æ¬¡è¿›åº¦
                current_time = time.time()
                if current_time - last_log_time > 5 and len(media_files) % 500 == 0:
                    logger.info(
                        f"æ‰«æè¿›åº¦: å·²æ‰¾åˆ° {len(media_files):,}ä¸ªæ–‡ä»¶ ({total_size / 1024 / 1024:.1f} MB)"
                    )
                    last_log_time = current_time

    # æ‰«æå®Œæˆ
    if skipped_dirs:
        logger.debug(f"âš ï¸ è·³è¿‡ {len(skipped_dirs)} ä¸ªç³»ç»Ÿç›®å½•")

    scan_time = time.time() - start_scan
    logger.info(
        f"ğŸ“Š æ‰«æå®Œæˆ! æ‰¾åˆ° {len(media_files):,}ä¸ªåª’ä½“æ–‡ä»¶ ({total_size / 1024 / 1024:.1f} MB) "
        f"è€—æ—¶: {scan_time:.1f}ç§’ ({len(media_files) / max(scan_time, 0.01):.1f}æ–‡ä»¶/ç§’)"
    )

    # æ²¡æœ‰æ–‡ä»¶æ—¶æå‰è¿”å›
    if not media_files:
        logger.info("â— æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„åª’ä½“æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
        return

    # 2. è®¾ç½®å…¨å±€ç»Ÿè®¡
    global_stats = ProcessingStats(total_files=len(media_files))

    # 3. å¹¶è¡Œå¤„ç†è®¡ç®—ç›®æ ‡è·¯å¾„
    logger.info("ğŸ§  è®¡ç®—ç›®æ ‡è·¯å¾„...")
    compute_tasks = []

    # è‡ªåŠ¨è®¡ç®—åˆé€‚çš„çº¿ç¨‹æ•°
    worker_count = max_workers or min(32, max(4, int(len(media_files) / 100) + 1))
    logger.info(f"ğŸ”§ ä½¿ç”¨ {worker_count} ä¸ªçº¿ç¨‹è¿›è¡Œæ—¥æœŸè®¡ç®—")

    # åˆ›å»ºè®¡ç®—è¿›åº¦æ¡
    with ProgressBar(total=len(media_files),
                     desc="è®¡ç®—æ–‡ä»¶æ—¥æœŸ",
                     unit="æ–‡ä»¶") as compute_bar:

        with concurrent.futures.ThreadPoolExecutor(max_workers=worker_count) as compute_executor:
            # æäº¤æ‰€æœ‰è®¡ç®—ä»»åŠ¡
            future_to_file = {}
            for file_info in media_files:
                future = compute_executor.submit(
                    calculate_target_path,
                    file_info,
                    target_base_dir,
                    global_stats,
                    compute_bar
                )
                future_to_file[future] = file_info[0]

            # æ‰¹é‡ç­‰å¾…ç»“æœ
            try:
                for future in concurrent.futures.as_completed(future_to_file):
                    filename = future_to_file[future]
                    try:
                        task = future.result()
                        if task:
                            compute_tasks.append(task)
                    except Exception as e:
                        logger.debug(f"è·¯å¾„è®¡ç®—é”™è¯¯ {filename}: {str(e)}")
            except KeyboardInterrupt:
                logger.warning("ç”¨æˆ·ä¸­æ­¢è®¡ç®—ä»»åŠ¡!")
                return

    # 4. å¤„ç†æ— æ•ˆ/è·³è¿‡çš„ä»»åŠ¡
    valid_tasks = [t for t in compute_tasks if t is not None]
    if len(valid_tasks) != len(media_files):
        diff = len(media_files) - len(valid_tasks)
        logger.info(f"âš ï¸ è·³è¿‡ {diff} ä¸ªæ–‡ä»¶ï¼ˆé‡å¤æˆ–æ— æ³•å¤„ç†ï¼‰")

    if not valid_tasks:
        logger.info("â— æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶éœ€è¦ç§»åŠ¨")
        return

    logger.info(f"ğŸš€ å¼€å§‹ç§»åŠ¨ {len(valid_tasks):,} ä¸ªæ–‡ä»¶...")

    # 5. å¹¶è¡Œå¤„ç†æ–‡ä»¶ç§»åŠ¨
    # I/Oæ“ä½œä½¿ç”¨è¾ƒå°‘çº¿ç¨‹
    io_workers = min(worker_count, 8)

    # ç§»åŠ¨è¿›åº¦æ¡
    total_bytes = sum(t[3] for t in valid_tasks)
    desc_text = f"ç§»åŠ¨æ–‡ä»¶ ({total_bytes / 1024 / 1024:.1f} MB)"

    with ProgressBar(total=len(valid_tasks), desc=desc_text, unit="æ–‡ä»¶") as move_bar:

        with concurrent.futures.ThreadPoolExecutor(max_workers=io_workers) as move_executor:
            # æäº¤æ‰€æœ‰ç§»åŠ¨ä»»åŠ¡
            io_futures = []
            for task in valid_tasks:
                future = move_executor.submit(
                    process_file,
                    task,
                    global_stats,
                    move_bar
                )
                io_futures.append(future)

            # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ŒåŒæ—¶æ¯åˆ†é’Ÿè®°å½•ä¸€æ¬¡è¯¦ç»†çŠ¶æ€
            while io_futures:
                # åˆ†æ‰¹ç­‰å¾…10ä¸ªå­ä»»åŠ¡å®Œæˆ
                batch = []
                for _ in range(min(64, len(io_futures))):
                    if io_futures:
                        batch.append(io_futures.pop(0))

                if batch:
                    _, done = concurrent.futures.wait(
                        batch,
                        timeout=5,
                        return_when=concurrent.futures.FIRST_COMPLETED
                    )

                    # å¤„ç†å·²å®Œæˆçš„å­ä»»åŠ¡
                    for future in list(done):
                        try:
                            future.result()  # è§¦å‘å¼‚å¸¸ï¼ˆå¦‚æœæœ‰ï¼‰
                        except Exception:
                            pass  # é”™è¯¯å·²åœ¨ä»»åŠ¡å†…éƒ¨å¤„ç†

                    # è®°å½•è¯¦ç»†è¿›åº¦
                    global_stats.log_progress()

    # 6. æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
    stats = global_stats.get_stats()
    elapsed = stats['elapsed']

    # è®¡ç®—å„ç§é€Ÿç‡
    file_rate = stats['processed'] / elapsed if elapsed > 0 else 0
    mb_rate = total_bytes / (1024 * 1024) / elapsed if elapsed > 0 else 0

    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    summary = [
        "=" * 70,
        "â­ æ•´ç†å®Œæˆ!",
        "=" * 70,
        f"ğŸ“Š ç»Ÿè®¡æ•°æ®:",
        f"  æ€»è€—æ—¶: {elapsed:.1f}ç§’",
        f"  å·²å¤„ç†: {stats['processed']}/{stats['total']} ({stats['processed'] / stats['total'] * 100:.1f}%)",
        f"  æˆåŠŸç§»åŠ¨: {stats['moved']}ä¸ªæ–‡ä»¶",
        f"  è·³è¿‡/é‡å¤: {stats['skipped']}ä¸ªæ–‡ä»¶",
        f"  å¤„ç†å¤±è´¥: {stats['failed']}ä¸ªæ–‡ä»¶",
        "",
        f"âš¡ æ€§èƒ½æŒ‡æ ‡:",
        f"  é€Ÿåº¦: {file_rate:.1f}æ–‡ä»¶/ç§’ | {mb_rate:.1f} MB/ç§’",
        "",
        f"ğŸ—‚ï¸ ç›®æ ‡ä½ç½®: {os.path.abspath(target_base_dir)}",
        "=" * 70
    ]

    for line in summary:
        logger.info(line)


def run_cli():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="ğŸ“¸ğŸ¥ åª’ä½“æ•´ç†å·¥å…· v7.0 - é«˜çº§è¿›åº¦æ¡ç‰ˆ",
        epilog="""ä½¿ç”¨ç¤ºä¾‹:
  åŸºæœ¬ç”¨æ³•: 
    python organizer.py 
  æŒ‡å®šæºç›®å½•: 
    python organizer.py --source ~/Photos
  æŒ‡å®šç›®æ ‡ç›®å½•: 
    python organizer.py --target ~/Sorted_Photos
  é«˜æ€§èƒ½æ¨¡å¼: 
    python organizer.py --workers 12
  è°ƒè¯•æ¨¡å¼: 
    python organizer.py --verbose""")

    parser.add_argument("--source", default=os.getcwd(),
                        help="æºç›®å½•ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰", metavar="PATH")
    parser.add_argument("--target", default=None,
                        help="ç›®æ ‡ç›®å½•ï¼ˆé»˜è®¤åœ¨æºç›®å½•ä¸­æ•´ç†ï¼‰", metavar="PATH")
    parser.add_argument("--verbose", action="store_true",
                        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰")
    parser.add_argument("--workers", type=int, default=8,
                        help="å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤8ï¼‰", metavar="N")

    # æ·»åŠ ASCIIè‰ºæœ¯æ¬¢è¿ç•Œé¢
    banner = r"""
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• 
â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—  â•šâ–ˆâ–ˆâ•”â•  
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•   â•šâ•â•   
    """

    args = parser.parse_args()

    print(f"\n\033[96m{banner}\033[0m")
    print(f"\033[96m{'=' * 70}\033[0m")
    print(f"ğŸ“·ğŸ“¹ åª’ä½“æ•´ç†å·¥å…· v7.0 - ä¸“ä¸šè¿›åº¦æ¡ç‰ˆ")
    print(f"\033[96m{'=' * 70}\033[0m")
    print(f"ğŸ” æºç›®å½•  : \033[92m{os.path.abspath(args.source)}\033[0m")
    if args.target:
        print(f"ğŸ“ ç›®æ ‡ç›®å½•: \033[92m{os.path.abspath(args.target)}\033[0m")
    else:
        print(f"ğŸ“ ç›®æ ‡ç›®å½•: \033[93mæºç›®å½•å†…æ•´ç†\033[0m")
    print(f"âš™ï¸  å¹¶è¡Œçº¿ç¨‹: \033[93m{args.workers}\033[0m")
    print(f"ğŸ”§ è¯¦ç»†æ¨¡å¼: \033[93m{'æ˜¯' if args.verbose else 'å¦'}\033[0m")
    print(f"\033[96m{'=' * 70}\033[0m\n")

    try:
        organize_media(
            source_dir=args.source,
            target_base_dir=args.target,
            verbose=args.verbose,
            max_workers=args.workers
        )
    except KeyboardInterrupt:
        print("\n\033[91mæ“ä½œè¢«ç”¨æˆ·ä¸­æ–­!\033[0m")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\033[91mç¨‹åºå‘ç”Ÿé”™è¯¯: {str(e)}\033[0m")
        if args.verbose:
            logger.debug(f"é”™è¯¯è¯¦æƒ…: {sys.exc_info()}")
        sys.exit(1)


if __name__ == "__main__":
    run_cli()
